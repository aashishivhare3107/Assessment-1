{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5c2cd0",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "In this notebook we will prepare our data for our search function to use.\n",
    "\n",
    "Currently we have data stored in four different csv files.\n",
    "\n",
    " 1.dirty_data.csv\n",
    " \n",
    " 2.missing_data.csv\n",
    " ### It can be computationally expensive to produce analysis results from multiple data-sources for incomming stream of requests.\n",
    "So we will prepare our data and save it in an easily searchable structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47f2362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed modules...\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a86408",
   "metadata": {},
   "source": [
    "# Define Paths to data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1a562c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_dirty_data   = f\"{getcwd()}/dataStore/dirty_data.csv\"\n",
    "PATH_missing_data  = f\"{getcwd()}/dataStore/missing_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65426f",
   "metadata": {},
   "source": [
    "# Data Engineering\n",
    "Get data in dataframes.\n",
    "\n",
    "Convert data to a single dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6c04635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['order_id', 'customer_id', 'date', 'nearest_warehouse', 'shopping_cart', 'order_price', 'delivery_charges', 'customer_lat', 'customer_long', 'coupon_discount', 'order_total', 'season', 'is_expedited_delivery', 'distance_to_nearest_warehouse', 'latest_customer_review', 'is_happy_customer']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from movies.csv\n",
    "\"\"\"\n",
    "df_dirty_data            = pd.read_csv(PATH_dirty_data)\n",
    "dirty_data_table_columns = df_dirty_data.columns.tolist()\n",
    "print(f\"COLUMNS : {dirty_data_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3823a372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['order_id', 'customer_id', 'date', 'nearest_warehouse', 'shopping_cart', 'order_price', 'delivery_charges', 'customer_lat', 'customer_long', 'coupon_discount', 'order_total', 'season', 'is_expedited_delivery', 'distance_to_nearest_warehouse', 'latest_customer_review', 'is_happy_customer']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from missing_data.csv\n",
    "\"\"\"\n",
    "df_missing_data            = pd.read_csv(PATH_missing_data)\n",
    "missing_data_table_columns = df_missing_data.columns.tolist()\n",
    "print(f\"COLUMNS : {missing_data_table_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334ffb5",
   "metadata": {},
   "source": [
    "### order_Id is a common column in all two tables so we will use it as a primary search-key\n",
    "### A user will always search a order by its customer_id so we will create a Global secondary index to be able to perform search our datastore.\n",
    "it will obviously take some extra space but almost negligible as compared to the size of the original data.\n",
    "In addition, It will make our searching faster and efficient so it's a good deal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7a97e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is True  that the column 'order_id' has unique values for all entries in dirty_data dataframe.\n",
      "It is True that the column 'order_id' has unique values for all entries in missing_data dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(f\"It is {pd.Series(df_dirty_data['order_id']).is_unique}  that the column 'order_id' has unique values for all entries in dirty_data dataframe.\")\n",
    "print(f\"It is {pd.Series(df_missing_data['order_id']).is_unique} that the column 'order_id' has unique values for all entries in missing_data dataframe.\")\n",
    "\n",
    "# Sort dirty_data dataframe on the basis of order_Id as order_Id is unique for all entries...\n",
    "df_dirty_data_sorted = df_dirty_data.sort_values(by=['order_id'])\n",
    "\n",
    "# Sort missing_data dataframe on the basis of order_Id as order_Id is unique for all entries...\n",
    "df_missing_data_sorted  = df_missing_data.sort_values(by=['order_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b026c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dirty_data dataframe...\n",
    "order_Id                         = df_dirty_data_sorted[\"order_id\"].tolist()\n",
    "customer_Id                      = df_dirty_data_sorted[\"customer_id\"].tolist()\n",
    "shoppingCart = [shoppingCart.split(\"|\") for shoppingCart in df_dirty_data[\"shopping_cart\"].tolist()]\n",
    "\n",
    "# from missing_data dataframe...\n",
    "latest_customer_review           = df_missing_data_sorted[\"latest_customer_review\"].tolist()\n",
    "is_happy_customer                = df_missing_data_sorted[\"is_happy_customer\"].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ba9374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataDict             = {}\n",
    "global_secondaryIndex      = {}\n",
    "for idx, order_id in enumerate(order_Id):\n",
    "    dirty_dataDict[order_id] = {\n",
    "        \"Cart\" :shoppingCart[idx],\n",
    "        \"missing_data\" : {\n",
    "                \"latest_customer_review\"     : latest_customer_review[idx],\n",
    "                \"is_happy_customer\"          : is_happy_customer[idx]\n",
    "\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    global_secondaryIndex[customer_id[idx]] = customer_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d74411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete veriables which are no longer in use while holding large amount of data.\n",
    "#del order_Id\n",
    "#del customer_Id\n",
    "#del shoppingCart\n",
    "#del latest_customer_review\n",
    "#del is_happy_customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b01410ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing dirty_data Data into the disk...\n",
      "[INFO] Writing Global Secondary Index Data into the disk...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"[INFO] Writing dirty_data Data into the disk...\")\n",
    "with open('dataStore/dataFinal.json', 'w') as fp:\n",
    "    json.dump(dirty_dataDict, fp, sort_keys=True, indent=4)\n",
    "print(\"[INFO] Writing Global Secondary Index Data into the disk...\")\n",
    "with open('dataStore/dataFinal_GIS.json', 'w') as fp:\n",
    "    json.dump(global_secondaryIndex, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe371f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
